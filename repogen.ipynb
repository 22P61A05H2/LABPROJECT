{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c3b4572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: torch in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: geopy in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.14.2)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pandas in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: easyocr in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2025.3.2)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SpeechRecognition) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SpeechRecognition) (0.2.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (4.11.0.86)\n",
      "Requirement already satisfied: scipy in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.15.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (0.25.2)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (0.6.6)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (2.1.0)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.11.1.4)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from standard-aifc->SpeechRecognition) (3.13.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow torch torchvision torchaudio requests geopy SpeechRecognition pytesseract pandas numpy easyocr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce28c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress: |██████████████████████████████████████████████████| 100.0% Complete"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jyoth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jyoth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Image Input ---\n",
      "\n",
      "--- Optional Inputs ---\n",
      "\n",
      "--- Generated Report ---\n",
      "--- Report ---\n",
      "\n",
      "Event: Algoveda\n",
      "College: Vignana Bharathi Institute of Technology,Ghatkesar,Hyderabad\n",
      "\n",
      "--- Image Analysis ---\n",
      "Image 1:\n",
      "- Object Detection: The image likely contains: stage (54.01%), balance beam (5.87%), scoreboard (5.40%), grand piano (3.82%), front curtain (3.38%).\n",
      "- Text Recognition: Recognized text:\n",
      "AlgoVeda\n",
      "VBIT\n",
      "AlgoVeda\n",
      "\n",
      "Image 2:\n",
      "- Object Detection: The image likely contains: stage (28.83%), balance beam (14.08%), scoreboard (14.04%), baseball player (3.85%), horizontal bar (3.24%).\n",
      "- Text Recognition: Recognized text:\n",
      "VBIT\n",
      "AlgoVeda\n",
      "\n",
      "\n",
      "--- Location Information ---\n",
      "Provided Location: Vignana Bharathi Institution of Technology,Aushapur,Ghatkesar,Hyderabad,Telangana,India\n",
      "College Name (from location): [Geocoding skipped as college name was provided]\n",
      "\n",
      "--- Feedback ---\n",
      "User Feedback: It was a nice coding competition\n",
      "\n",
      "--- End of Report ---\n",
      "\n",
      "Report saved to 'report_20250426_154812.txt'\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import requests\n",
    "import json\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "import speech_recognition as sr\n",
    "from datetime import datetime\n",
    "import easyocr  # Import the easyocr library\n",
    "\n",
    "# Initialize easyocr reader ONCE\n",
    "try:\n",
    "    reader = easyocr.Reader(['en'])  # You can add other languages here, e.g., ['en', 'hi']\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing easyocr: {e}\")\n",
    "    reader = None\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"multimedia_report_generator\")\n",
    "\n",
    "# Initialize speech recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Load pre-trained model and labels ONCE\n",
    "model = None\n",
    "transform = None\n",
    "imagenet_classes = []\n",
    "try:\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    try:\n",
    "        with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "            imagenet_classes = [s.strip() for s in f.readlines()]\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: imagenet_classes.txt not found. Downloading...\")\n",
    "        url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            imagenet_labels_json = response.json()\n",
    "            if isinstance(imagenet_labels_json, dict):\n",
    "                imagenet_classes = list(imagenet_labels_json.values())\n",
    "            elif isinstance(imagenet_labels_json, list):\n",
    "                imagenet_classes = imagenet_labels_json\n",
    "            else:\n",
    "                print(\"Error: Unexpected format for downloaded ImageNet labels.\")\n",
    "                imagenet_classes = [\"unknown\"] * 1000\n",
    "            with open(\"imagenet_classes.txt\", \"w\") as f:\n",
    "                for label in imagenet_classes:\n",
    "                    f.write(label + \"\\n\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading ImageNet labels: {e}\")\n",
    "            imagenet_classes = [\"unknown\"] * 1000\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding downloaded JSON: {e}\")\n",
    "            imagenet_classes = [\"unknown\"] * 1000\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ImageNet class labels: {e}\")\n",
    "        imagenet_classes = [\"unknown\"] * 1000\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing PyTorch models or transforms: {e}\")\n",
    "    model = None\n",
    "    transform = None\n",
    "    imagenet_classes = [\"Error\"] * 1000\n",
    "\n",
    "def get_input_paths():\n",
    "    input_paths = {}\n",
    "\n",
    "    # Event Name (Mandatory)\n",
    "    event_name = input(\"Enter the name of the event: \")\n",
    "    input_paths['event_name'] = event_name\n",
    "\n",
    "    # Image Input (Mandatory)\n",
    "    image_paths = []\n",
    "    print(\"\\n--- Image Input ---\")\n",
    "    while True:\n",
    "        image_path = input(\"Enter the path to an image file (or type 'done' if you've entered all images): \")\n",
    "        if image_path.lower() == 'done':\n",
    "            break\n",
    "        if os.path.exists(image_path):\n",
    "            image_paths.append(image_path)\n",
    "        else:\n",
    "            print(f\"Error: Image path '{image_path}' does not exist.\")\n",
    "    if not image_paths:\n",
    "        print(\"Error: At least one image is required.\")\n",
    "        return None\n",
    "    input_paths['images'] = image_paths\n",
    "\n",
    "    # College Name (Mandatory)\n",
    "    college_name_input = input(\"Enter the name of the college: \")\n",
    "    input_paths['college_name'] = college_name_input\n",
    "\n",
    "    # Optional Inputs\n",
    "    print(\"\\n--- Optional Inputs ---\")\n",
    "    analyze_objects = input(\"Do you want to analyze objects in the image? (yes/no): \").lower()\n",
    "    input_paths['analyze_objects'] = analyze_objects == 'yes'\n",
    "\n",
    "    recognize_text = input(\"Do you want to recognize text in the image? (yes/no): \").lower()\n",
    "    input_paths['recognize_text'] = recognize_text == 'yes'\n",
    "\n",
    "    add_audio = input(\"Do you want to provide an audio file or speak now? (file/live/no): \").lower()\n",
    "    if add_audio == 'file':\n",
    "        audio_path = input(\"Enter the path to the audio file: \")\n",
    "        if os.path.exists(audio_path):\n",
    "            input_paths['audio'] = audio_path\n",
    "        else:\n",
    "            print(f\"Error: Audio path '{audio_path}' does not exist.\")\n",
    "    elif add_audio == 'live':\n",
    "        input_paths['audio'] = 'live'  # Use a special string to indicate live input\n",
    "\n",
    "    add_feedback = input(\"Do you want to provide feedback text? (yes/no): \").lower()\n",
    "    if add_feedback == 'yes':\n",
    "        feedback_text = input(\"Enter the feedback text: \")\n",
    "        input_paths['feedback'] = feedback_text\n",
    "\n",
    "    add_location = input(\"Do you want to provide location information? (yes/no): \").lower()\n",
    "    if add_location == 'yes':\n",
    "        location_input = input(\"Enter the location (e.g., latitude,longitude or a place name): \")\n",
    "        input_paths['location'] = location_input\n",
    "\n",
    "    return input_paths\n",
    "\n",
    "def process_image_objects(image_path):\n",
    "    if model is None or transform is None or not imagenet_classes or \"Error\" in imagenet_classes:\n",
    "        return \"Error: PyTorch model or dependencies not initialized correctly.\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_t = transform(img)\n",
    "        batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(batch_t)\n",
    "\n",
    "        _, indices = torch.sort(output, descending=True)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "\n",
    "        top5_preds = [(imagenet_classes[idx], probabilities[idx].item() * 100) for idx in indices[0][:5]]\n",
    "        description = f\"The image likely contains: {', '.join([f'{pred[0]} ({pred[1]:.2f}%)' for pred in top5_preds])}.\"\n",
    "        return description\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Image file not found at '{image_path}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image '{image_path}' for object detection: {e}\"\n",
    "\n",
    "def process_image_text(image_path):\n",
    "    if reader is None:\n",
    "        return \"Error: easyocr not initialized.\"\n",
    "    try:\n",
    "        result = reader.readtext(image_path)\n",
    "        if result:\n",
    "            recognized_text = \"\\n\".join([detection[1] for detection in result])\n",
    "            return f\"Recognized text:\\n{recognized_text}\"\n",
    "        else:\n",
    "            return \"No text recognized in the image.\"\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Image file not found at '{image_path}' for text recognition.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image '{image_path}' for text recognition with easyocr: {e}\"\n",
    "\n",
    "# Consider implementing a simple cache for geocoding if repeated locations are expected\n",
    "# geocode_cache = {}\n",
    "\n",
    "def get_college_name_from_location(location_str):\n",
    "    # if location_str in geocode_cache:\n",
    "    #     return geocode_cache[location_str]\n",
    "    try:\n",
    "        college = None\n",
    "        if \",\" in location_str:\n",
    "            lat_str, lon_str = location_str.split(',')\n",
    "            try:\n",
    "                latitude = float(lat_str.strip())\n",
    "                longitude = float(lon_str.strip())\n",
    "                location = geolocator.reverse((latitude, longitude), exactly_one=True, language=\"en\")\n",
    "                if location and location.raw.get('address'):\n",
    "                    address = location.raw['address']\n",
    "                    college = address.get('university') or address.get('college')\n",
    "            except ValueError:\n",
    "                return \"Error: Invalid latitude/longitude format.\"\n",
    "        else:\n",
    "            location = geolocator.geocode(location_str, exactly_one=True, language=\"en\")\n",
    "            if location and location.raw.get('address'):\n",
    "                address = location.raw['address']\n",
    "                college = address.get('university') or address.get('college')\n",
    "\n",
    "        result = college if college else \"[College name not found based on location]\"\n",
    "        # geocode_cache[location_str] = result\n",
    "        return result\n",
    "    except (GeocoderTimedOut, GeocoderServiceError) as e:\n",
    "        # geocode_cache[location_str] = f\"Error with geocoding service: {e}\"\n",
    "        return f\"Error with geocoding service: {e}\"\n",
    "    except Exception as e:\n",
    "        # geocode_cache[location_str] = f\"An unexpected error occurred during geocoding: {e}\"\n",
    "        return f\"An unexpected error occurred during geocoding: {e}\"\n",
    "\n",
    "def process_audio(audio_input):\n",
    "    if audio_input == 'live':\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Speak now...\")\n",
    "            try:\n",
    "                audio_data = r.listen(source)\n",
    "                text = r.recognize_google(audio_data)\n",
    "                return f\"Live audio transcript: {text}\"\n",
    "            except sr.UnknownValueError:\n",
    "                return \"Could not understand audio.\"\n",
    "            except sr.RequestError as e:\n",
    "                return f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "            except Exception as e:\n",
    "                return f\"Error processing live audio: {e}\"\n",
    "    else:\n",
    "        try:\n",
    "            with sr.AudioFile(audio_input) as source:\n",
    "                audio_data = r.record(source)\n",
    "                try:\n",
    "                    text = r.recognize_google(audio_data)\n",
    "                    return f\"Audio transcript: {text}\"\n",
    "                except sr.UnknownValueError:\n",
    "                    return \"Could not understand audio from file.\"\n",
    "                except sr.RequestError as e:\n",
    "                    return f\"Could not request results from Google Speech Recognition service (file); {e}\"\n",
    "        except FileNotFoundError:\n",
    "            return f\"Error: Audio file not found at '{audio_input}'.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing audio file '{audio_input}': {e}\"\n",
    "\n",
    "def generate_report(inputs):\n",
    "    report_content = \"\"\n",
    "\n",
    "    event_name = inputs.get('event_name', '[Event Name not provided]')\n",
    "    college_name = inputs.get('college_name', '[College Name not provided]')\n",
    "\n",
    "    final_report = f\"--- Report ---\\n\\n\"\n",
    "    final_report += f\"Event: {event_name}\\n\"\n",
    "    final_report += f\"College: {college_name}\\n\\n\"\n",
    "\n",
    "    if 'images' in inputs and inputs['images']:\n",
    "        final_report += \"--- Image Analysis ---\\n\"\n",
    "        for i, image_path in enumerate(inputs['images']):\n",
    "            image_report = f\"Image {i+1}:\\n\"\n",
    "            if inputs.get('analyze_objects', False):\n",
    "                object_description = process_image_objects(image_path)\n",
    "                image_report += f\"- Object Detection: {object_description}\\n\"\n",
    "            if inputs.get('recognize_text', False):\n",
    "                text_description = process_image_text(image_path)\n",
    "                image_report += f\"- Text Recognition: {text_description}\\n\"\n",
    "            final_report += image_report + \"\\n\"\n",
    "        final_report += \"\\n\"\n",
    "\n",
    "    if 'location' in inputs:\n",
    "        final_report += \"--- Location Information ---\\n\"\n",
    "        final_report += f\"Provided Location: {inputs['location']}\\n\"\n",
    "        # Only call geocoding if a college name wasn't directly provided or if you specifically need the location's college\n",
    "        if college_name == '[College Name not provided]':\n",
    "            college_name_from_location = get_college_name_from_location(inputs['location'])\n",
    "            final_report += f\"College Name (from location): {college_name_from_location}\\n\\n\"\n",
    "        else:\n",
    "            final_report += f\"College Name (from location): [Geocoding skipped as college name was provided]\\n\\n\"\n",
    "\n",
    "    if 'feedback' in inputs:\n",
    "        final_report += \"--- Feedback ---\\n\"\n",
    "        final_report += f\"User Feedback: {inputs['feedback']}\\n\\n\"\n",
    "\n",
    "    if 'audio' in inputs:\n",
    "        final_report += \"--- Audio Information ---\\n\"\n",
    "        if inputs['audio'] == 'live':\n",
    "            final_report += \"Audio Source: Live Microphone Input\\n\"\n",
    "        else:\n",
    "            final_report += f\"Audio Path: {inputs['audio']}\\n\"\n",
    "        audio_transcript = process_audio(inputs['audio'])\n",
    "        final_report += f\"Audio Transcript: {audio_transcript}\\n\\n\"\n",
    "\n",
    "    final_report += \"--- End of Report ---\"\n",
    "\n",
    "    return final_report\n",
    "\n",
    "def save_report_to_file(report):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"report_{timestamp}.txt\"\n",
    "    try:\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(report)\n",
    "        print(f\"\\nReport saved to '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving report to file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = get_input_paths()\n",
    "    if inputs and 'images' in inputs:\n",
    "        report = generate_report(inputs)\n",
    "        print(\"\\n--- Generated Report ---\")\n",
    "        print(report)\n",
    "        save_report_to_file(report)\n",
    "    else:\n",
    "        print(\"No valid inputs received. Cannot generate a report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "015e9ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.1.0)\n",
      "Requirement already satisfied: google-generativeai in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.8.5)\n",
      "Requirement already satisfied: google-ai-generativelanguage==0.6.15 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (0.6.15)\n",
      "Requirement already satisfied: google-api-core in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.25.0rc0)\n",
      "Requirement already satisfied: google-api-python-client in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.168.0)\n",
      "Requirement already satisfied: google-auth>=2.15.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.39.0)\n",
      "Requirement already satisfied: protobuf in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (5.29.4)\n",
      "Requirement already satisfied: pydantic in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (2.11.3)\n",
      "Requirement already satisfied: tqdm in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (4.67.1)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-generativeai) (4.13.2)\n",
      "Requirement already satisfied: proto-plus<2.0.0dev,>=1.22.3 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-ai-generativelanguage==0.6.15->google-generativeai) (1.26.1)\n",
      "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core->google-generativeai) (1.70.0)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.18.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core->google-generativeai) (2.32.3)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (5.5.2)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (0.4.2)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-auth>=2.15.0->google-generativeai) (4.9.1)\n",
      "Requirement already satisfied: httplib2<1.0.0,>=0.19.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.22.0)\n",
      "Requirement already satisfied: google-auth-httplib2<1.0.0,>=0.2.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai) (0.2.0)\n",
      "Requirement already satisfied: uritemplate<5,>=3.0.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-python-client->google-generativeai) (4.1.1)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.33.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (2.33.1)\n",
      "Requirement already satisfied: typing-inspection>=0.4.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pydantic->google-generativeai) (0.4.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from tqdm->google-generativeai) (0.4.6)\n",
      "Requirement already satisfied: grpcio<2.0.0,>=1.33.2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: grpcio-status<2.0.0,>=1.33.2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from google-api-core[grpc]!=2.0.*,!=2.1.*,!=2.10.*,!=2.2.*,!=2.3.*,!=2.4.*,!=2.5.*,!=2.6.*,!=2.7.*,!=2.8.*,!=2.9.*,<3.0.0dev,>=1.34.1->google-ai-generativelanguage==0.6.15->google-generativeai) (1.71.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.0,!=3.0.1,!=3.0.2,!=3.0.3,<4,>=2.4.2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from httplib2<1.0.0,>=0.19.0->google-api-python-client->google-generativeai) (3.2.3)\n",
      "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyasn1-modules>=0.2.1->google-auth>=2.15.0->google-generativeai) (0.6.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests<3.0.0,>=2.18.0->google-api-core->google-generativeai) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install python-dotenv google-generativeai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2c590e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error generating report with Gemini: 400 API key not valid. Please pass a valid API key. [reason: \"API_KEY_INVALID\"\n",
      "domain: \"googleapis.com\"\n",
      "metadata {\n",
      "  key: \"service\"\n",
      "  value: \"generativelanguage.googleapis.com\"\n",
      "}\n",
      ", locale: \"en-US\"\n",
      "message: \"API key not valid. Please pass a valid API key.\"\n",
      "]\n",
      "Failed to generate report using Gemini.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import google.generativeai as genai\n",
    "\n",
    "# Load environment variables from .env file\n",
    "load_dotenv()\n",
    "GEMINI_API_KEY = os.getenv('GEMINI_API_KEY')\n",
    "\n",
    "# Configure the Gemini API if the key is available\n",
    "if GEMINI_API_KEY:\n",
    "    genai.configure(api_key=GEMINI_API_KEY)\n",
    "    model_gemini = genai.GenerativeModel('gemini-pro')\n",
    "else:\n",
    "    print(\"Warning: GEMINI_API_KEY not found in .env file. Gemini functionality will be disabled.\")\n",
    "    model_gemini = None\n",
    "\n",
    "def generate_report_with_gemini(report_data):\n",
    "    \"\"\"\n",
    "    Generates a report using the Gemini API based on the provided data.\n",
    "\n",
    "    Args:\n",
    "        report_data (str): A string containing the structured information\n",
    "                           to be included in the report.\n",
    "\n",
    "    Returns:\n",
    "        str: The generated report text, or None if an error occurred\n",
    "             or the Gemini API key is not configured.\n",
    "    \"\"\"\n",
    "    if model_gemini:\n",
    "        prompt = f\"Generate a concise report based on the following data:\\n\\n{report_data}\"\n",
    "        try:\n",
    "            response = model_gemini.generate_content(prompt)\n",
    "            return response.text\n",
    "        except Exception as e:\n",
    "            print(f\"Error generating report with Gemini: {e}\")\n",
    "            return None\n",
    "    else:\n",
    "        return \"Gemini API key not configured. Cannot generate report.\"\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Example of report data you might have collected from other parts of your script\n",
    "    report_information = f\"\"\"\n",
    "    Event: Sample Event\n",
    "    College: Example College\n",
    "    Image Analysis: Image 1 - Likely contains: cat (90%), dog (5%).\n",
    "                    Image 1 - Recognized text: Welcome!\n",
    "    Location: Hyderabad, India\n",
    "    Feedback: User liked the event.\n",
    "    Audio Transcript: The speaker discussed the main points...\n",
    "    \"\"\"\n",
    "\n",
    "    if model_gemini:\n",
    "        generated_report = generate_report_with_gemini(report_information)\n",
    "        if generated_report:\n",
    "            print(\"\\n--- Generated Report (using Gemini) ---\")\n",
    "            print(generated_report)\n",
    "        else:\n",
    "            print(\"Failed to generate report using Gemini.\")\n",
    "    else:\n",
    "        print(\"Gemini API is not configured. Skipping report generation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33afd26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import mysql.connector\n",
    "\n",
    "# Database configuration\n",
    "DB_HOST = \"localhost\"\n",
    "DB_USER = \"root\"  # Replace with your MySQL username\n",
    "DB_PASSWORD = \"Adithya@2005\"  # Replace with your MySQL password\n",
    "DB_NAME = \"project1\"\n",
    "\n",
    "def create_tables():\n",
    "    try:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=DB_HOST,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            database=DB_NAME\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "\n",
    "        # Create input table if it doesn't exist\n",
    "        mycursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS input (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                extracted_features_path VARCHAR(255),\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # Create output table if it doesn't exist\n",
    "        mycursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS output (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                input_id INT,\n",
    "                report_content TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                FOREIGN KEY (input_id) REFERENCES input(id)\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        mydb.commit()\n",
    "        mycursor.close()\n",
    "        mydb.close()\n",
    "        print(\"Database tables 'input' and 'output' created (if they didn't exist).\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error creating tables: {err}\")\n",
    "\n",
    "def get_input_paths():\n",
    "    input_paths = {}\n",
    "    extracted_features_path = input(\"Enter the path to the file containing extracted features (.txt): \").strip()\n",
    "\n",
    "    if not os.path.exists(extracted_features_path):\n",
    "        print(f\"Error: File not found at '{extracted_features_path}'.\")\n",
    "        return None\n",
    "    input_paths['extracted_features_path'] = extracted_features_path\n",
    "    return input_paths\n",
    "\n",
    "def insert_input_data(inputs):\n",
    "    try:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=DB_HOST,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            database=DB_NAME\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "\n",
    "        sql = \"INSERT INTO input (extracted_features_path) VALUES (%s)\"\n",
    "        val = (inputs.get('extracted_features_path'),)\n",
    "        mycursor.execute(sql, val)\n",
    "        mydb.commit()\n",
    "        input_id = mycursor.lastrowid\n",
    "        mycursor.close()\n",
    "        mydb.close()\n",
    "        return input_id\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error inserting input data: {err}\")\n",
    "        return None\n",
    "\n",
    "def insert_output_data(input_id, report):\n",
    "    try:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=DB_HOST,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            database=DB_NAME\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "\n",
    "        sql = \"INSERT INTO output (input_id, report_content) VALUES (%s, %s)\"\n",
    "        val = (input_id, report)\n",
    "        mycursor.execute(sql, val)\n",
    "        mydb.commit()\n",
    "        mycursor.close()\n",
    "        mydb.close()\n",
    "        print(\"Report content saved to the 'output' table.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error inserting output data: {err}\")\n",
    "\n",
    "def generate_paragraph_report(inputs):\n",
    "    extracted_features_path = inputs.get('extracted_features_path')\n",
    "    report_paragraph = \"\"\n",
    "\n",
    "    try:\n",
    "        with open(extracted_features_path, \"r\") as f:\n",
    "            extracted_features = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "        if extracted_features:\n",
    "            report_paragraph += \"The analysis of the provided data reveals several key characteristics. \"\n",
    "            report_paragraph += \", \".join(extracted_features) + \". \"\n",
    "\n",
    "            # Generate AI content based on extracted features\n",
    "            ai_elaboration = []\n",
    "            for feature in extracted_features:\n",
    "                if \"image contains\" in feature.lower():\n",
    "                    entity = feature.split(\"contains\")[-1].strip()\n",
    "                    ai_elaboration.append(f\"The presence of a '{entity}' suggests a visual focus on this element, potentially indicating its importance within the context.\")\n",
    "                elif \"dominant color\" in feature.lower():\n",
    "                    color = feature.split(\"is\")[-1].strip()\n",
    "                    ai_elaboration.append(f\"The dominant color being '{color}' could influence the overall mood or convey specific symbolic meanings.\")\n",
    "                elif \"detected object\" in feature.lower():\n",
    "                    obj = feature.split(\":\")[-1].strip()\n",
    "                    ai_elaboration.append(f\"The detection of a '{obj}' as a significant object warrants further consideration of its role.\")\n",
    "                elif \"confidence score\" in feature.lower():\n",
    "                    score = float(feature.split(':')[-1].strip())\n",
    "                    if score > 0.8:\n",
    "                        ai_elaboration.append(f\"With a high confidence score of {score:.2f}, this particular observation is deemed highly reliable.\")\n",
    "                    else:\n",
    "                        ai_elaboration.append(f\"The confidence score of {score:.2f} suggests a moderate level of certainty for this finding.\")\n",
    "                else:\n",
    "                    ai_elaboration.append(f\"This feature contributes to the overall understanding and may hold further implications.\")\n",
    "\n",
    "            if ai_elaboration:\n",
    "                report_paragraph += \"Considering these individual findings, a broader interpretation emerges. \"\n",
    "                report_paragraph += \" \".join(random.sample(ai_elaboration, min(len(ai_elaboration), 2))) + \". \"\n",
    "\n",
    "            report_paragraph = report_paragraph.strip()\n",
    "            # Ensure at least 3 lines (by adding more sentences)\n",
    "            while report_paragraph.count('.') < 2 and ai_elaboration:\n",
    "                report_paragraph += random.choice(ai_elaboration) + \". \"\n",
    "                report_paragraph = report_paragraph.strip()\n",
    "\n",
    "            if report_paragraph.count('.') < 2:\n",
    "                report_paragraph += \"In conclusion, the identified features collectively offer valuable insights into the subject matter.\"\n",
    "\n",
    "        else:\n",
    "            report_paragraph = \"No extracted features were found in the provided file.\"\n",
    "\n",
    "        return report_paragraph.strip()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: Extracted features file not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading extracted features file: {e}\"\n",
    "\n",
    "def save_report_to_file(report):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"report_{timestamp}.txt\"\n",
    "    try:\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(report)\n",
    "        print(f\"\\nReport saved to '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving report to file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create the tables if they don't exist\n",
    "    create_tables()\n",
    "\n",
    "    inputs = get_input_paths()\n",
    "    if inputs:\n",
    "        input_id = insert_input_data(inputs)\n",
    "        if input_id:\n",
    "            report = generate_paragraph_report(inputs)\n",
    "            print(\"\\n--- Generated Report ---\")\n",
    "            # Print the report with line breaks for better readability\n",
    "            formatted_report = \"\"\n",
    "            sentence_endings = ['.', '!', '?']\n",
    "            current_line = \"\"\n",
    "            for word in report.split():\n",
    "                if len(current_line) + len(word) + 1 <= 70:  # Adjust line width as needed\n",
    "                    current_line += (word + \" \")\n",
    "                else:\n",
    "                    formatted_report += current_line.strip() + \"\\n\"\n",
    "                    current_line = word + \" \"\n",
    "            formatted_report += current_line.strip()\n",
    "            print(formatted_report)\n",
    "            save_report_to_file(report)\n",
    "            insert_output_data(input_id, report)\n",
    "        else:\n",
    "            print(\"Failed to record input data.\")\n",
    "    else:\n",
    "        print(\"No valid input received.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
