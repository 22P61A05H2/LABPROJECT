{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6c3b4572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Pillow in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (10.4.0)\n",
      "Requirement already satisfied: torch in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: torchvision in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.21.0)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.6.0)\n",
      "Requirement already satisfied: requests in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.32.3)\n",
      "Requirement already satisfied: geopy in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.4.1)\n",
      "Requirement already satisfied: SpeechRecognition in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (3.14.2)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pandas in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.2.4)\n",
      "Requirement already satisfied: easyocr in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: pyaudio in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (0.2.14)\n",
      "Requirement already satisfied: pyttsx3 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.98)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.11.0.86)\n",
      "Collecting pydub\n",
      "  Downloading pydub-0.25.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: filelock in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.4.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (2024.12.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (78.1.0)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from sympy==1.13.1->torch) (1.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.4.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.1.31)\n",
      "Requirement already satisfied: geographiclib<3,>=1.52 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from geopy) (2.0)\n",
      "Requirement already satisfied: standard-aifc in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SpeechRecognition) (3.13.0)\n",
      "Requirement already satisfied: audioop-lts in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from SpeechRecognition) (0.2.1)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pytesseract) (24.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: opencv-python-headless in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (4.11.0.86)\n",
      "Requirement already satisfied: scipy in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.15.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (0.25.2)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (0.6.6)\n",
      "Requirement already satisfied: PyYAML in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (6.0.2)\n",
      "Requirement already satisfied: Shapely in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (2.1.0)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from easyocr) (1.11.1.4)\n",
      "Requirement already satisfied: comtypes in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyttsx3) (1.4.10)\n",
      "Requirement already satisfied: pypiwin32 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from pyttsx3) (223)\n",
      "Requirement already satisfied: pywin32 in c:\\users\\jyoth\\appdata\\roaming\\python\\python313\\site-packages (from pyttsx3) (308)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from jinja2->torch) (3.0.2)\n",
      "Requirement already satisfied: imageio!=2.35.0,>=2.33 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (2025.3.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: standard-chunk in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from standard-aifc->SpeechRecognition) (3.13.0)\n",
      "Downloading pydub-0.25.1-py2.py3-none-any.whl (32 kB)\n",
      "Installing collected packages: pydub\n",
      "Successfully installed pydub-0.25.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install Pillow torch torchvision torchaudio requests geopy SpeechRecognition pytesseract pandas numpy easyocr pyaudio pyttsx3 opencv-python pydub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce28c312",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jyoth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydub\\utils.py:170: RuntimeWarning: Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\n",
      "  warn(\"Couldn't find ffmpeg or avconv - defaulting to ffmpeg, but may not work\", RuntimeWarning)\n",
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\jyoth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jyoth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Image Input ---\n",
      "\n",
      "--- Optional Inputs ---\n",
      "Attempting to process audio file: C:\\Users\\jyoth\\Downloads\\WhatsApp Audio 2025-04-28 at 18.54.39_77355729.waptt.mp3\n",
      "\n",
      "--- Generated Report ---\n",
      "--- Report ---\n",
      "\n",
      "Event: Algoveda\n",
      "College: VBIT\n",
      "\n",
      "--- Image Analysis ---\n",
      "Image 1:\n",
      "- Text Recognition: Recognized text:\n",
      "AlgoVeda\n",
      "VBIT\n",
      "AlgoVeda\n",
      "\n",
      "Image 2:\n",
      "- Text Recognition: Recognized text:\n",
      "VBIT\n",
      "AlgoVeda\n",
      "\n",
      "\n",
      "--- Location Information ---\n",
      "Provided Location:  Vignana Bharathi Institute of Technology,Ghatkesar,Hyderabad\n",
      "College Name (from location): [Geocoding skipped as college name was provided]\n",
      "\n",
      "--- Feedback ---\n",
      "User Feedback: It was a nice coding competition\n",
      "\n",
      "--- Audio Information ---\n",
      "Audio Path: C:\\Users\\jyoth\\Downloads\\WhatsApp Audio 2025-04-28 at 18.54.39_77355729.waptt.mp3\n",
      "Audio Transcript: Error: Audio file not found at 'C:\\Users\\jyoth\\Downloads\\WhatsApp Audio 2025-04-28 at 18.54.39_77355729.waptt.mp3'.\n",
      "\n",
      "--- End of Report ---\n",
      "\n",
      "Report saved to 'report_20250430_211700.txt'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\jyoth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\pydub\\utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n"
     ]
    }
   ],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import requests\n",
    "import json\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "import speech_recognition as sr\n",
    "from datetime import datetime\n",
    "import easyocr  # Import the easyocr library\n",
    "from pydub import AudioSegment  # Import pydub for audio format conversion\n",
    "\n",
    "# Initialize easyocr reader ONCE\n",
    "try:\n",
    "    reader = easyocr.Reader(['en'])  # You can add other languages here, e.g., ['en', 'hi']\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing easyocr: {e}\")\n",
    "    reader = None\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"multimedia_report_generator\")\n",
    "\n",
    "# Initialize speech recognizer\n",
    "r = sr.Recognizer()\n",
    "\n",
    "# Load pre-trained model and labels ONCE\n",
    "model = None\n",
    "transform = None\n",
    "imagenet_classes = []\n",
    "try:\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    try:\n",
    "        with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "            imagenet_classes = [s.strip() for s in f.readlines()]\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: imagenet_classes.txt not found. Downloading...\")\n",
    "        url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            imagenet_labels_json = response.json()\n",
    "            if isinstance(imagenet_labels_json, dict):\n",
    "                imagenet_classes = list(imagenet_labels_json.values())\n",
    "            elif isinstance(imagenet_labels_json, list):\n",
    "                imagenet_classes = imagenet_labels_json\n",
    "            else:\n",
    "                print(\"Error: Unexpected format for downloaded ImageNet labels.\")\n",
    "                imagenet_classes = [\"unknown\"] * 1000\n",
    "            with open(\"imagenet_classes.txt\", \"w\") as f:\n",
    "                for label in imagenet_classes:\n",
    "                    f.write(label + \"\\n\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading ImageNet labels: {e}\")\n",
    "            imagenet_classes = [\"unknown\"] * 1000\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding downloaded JSON: {e}\")\n",
    "            imagenet_classes = [\"unknown\"] * 1000\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ImageNet class labels: {e}\")\n",
    "        imagenet_classes = [\"unknown\"] * 1000\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing PyTorch models or transforms: {e}\")\n",
    "    model = None\n",
    "    transform = None\n",
    "    imagenet_classes = [\"Error\"] * 1000\n",
    "\n",
    "def get_input_paths():\n",
    "    input_paths = {}\n",
    "\n",
    "    # Event Name (Mandatory)\n",
    "    event_name = input(\"Enter the name of the event: \")\n",
    "    input_paths['event_name'] = event_name\n",
    "\n",
    "    # Image Input (Mandatory)\n",
    "    image_paths = []\n",
    "    print(\"\\n--- Image Input ---\")\n",
    "    while True:\n",
    "        image_path = input(\"Enter the path to an image file (or type 'done' if you've entered all images): \")\n",
    "        if image_path.lower() == 'done':\n",
    "            break\n",
    "        if os.path.exists(image_path):\n",
    "            image_paths.append(image_path)\n",
    "        else:\n",
    "            print(f\"Error: Image path '{image_path}' does not exist.\")\n",
    "    if not image_paths:\n",
    "        print(\"Error: At least one image is required.\")\n",
    "        return None\n",
    "    input_paths['images'] = image_paths\n",
    "\n",
    "    # College Name (Mandatory)\n",
    "    college_name_input = input(\"Enter the name of the college: \")\n",
    "    input_paths['college_name'] = college_name_input\n",
    "\n",
    "    # Optional Inputs\n",
    "    print(\"\\n--- Optional Inputs ---\")\n",
    "    analyze_objects = input(\"Do you want to analyze objects in the image? (yes/no): \").lower()\n",
    "    input_paths['analyze_objects'] = analyze_objects == 'yes'\n",
    "\n",
    "    recognize_text = input(\"Do you want to recognize text in the image? (yes/no): \").lower()\n",
    "    input_paths['recognize_text'] = recognize_text == 'yes'\n",
    "\n",
    "    add_audio = input(\"Do you want to provide an audio file or speak now? (file/live/no): \").lower()\n",
    "    if add_audio == 'file':\n",
    "        audio_path = input(\"Enter the path to the audio file: \")\n",
    "        if os.path.exists(audio_path):\n",
    "            input_paths['audio'] = audio_path\n",
    "        else:\n",
    "            print(f\"Error: Audio path '{audio_path}' does not exist.\")\n",
    "    elif add_audio == 'live':\n",
    "        input_paths['audio'] = 'live'  # Use a special string to indicate live input\n",
    "\n",
    "    add_feedback = input(\"Do you want to provide feedback text? (yes/no): \").lower()\n",
    "    if add_feedback == 'yes':\n",
    "        feedback_text = input(\"Enter the feedback text: \")\n",
    "        input_paths['feedback'] = feedback_text\n",
    "\n",
    "    add_location = input(\"Do you want to provide location information? (yes/no): \").lower()\n",
    "    if add_location == 'yes':\n",
    "        location_input = input(\"Enter the location (e.g., latitude,longitude or a place name): \")\n",
    "        input_paths['location'] = location_input\n",
    "\n",
    "    return input_paths\n",
    "\n",
    "def process_image_objects(image_path):\n",
    "    if model is None or transform is None or not imagenet_classes or \"Error\" in imagenet_classes:\n",
    "        return \"Error: PyTorch model or dependencies not initialized correctly.\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_t = transform(img)\n",
    "        batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(batch_t)\n",
    "\n",
    "        _, indices = torch.sort(output, descending=True)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "\n",
    "        top5_preds = [(imagenet_classes[idx], probabilities[idx].item() * 100) for idx in indices[0][:5]]\n",
    "        description = f\"The image likely contains: {', '.join([f'{pred[0]} ({pred[1]:.2f}%)' for pred in top5_preds])}.\"\n",
    "        return description\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Image file not found at '{image_path}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image '{image_path}' for object detection: {e}\"\n",
    "\n",
    "def process_image_text(image_path):\n",
    "    if reader is None:\n",
    "        return \"Error: easyocr not initialized.\"\n",
    "    try:\n",
    "        result = reader.readtext(image_path)\n",
    "        if result:\n",
    "            recognized_text = \"\\n\".join([detection[1] for detection in result])\n",
    "            return f\"Recognized text:\\n{recognized_text}\"\n",
    "        else:\n",
    "            return \"No text recognized in the image.\"\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Image file not found at '{image_path}' for text recognition.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image '{image_path}' for text recognition with easyocr: {e}\"\n",
    "\n",
    "# Consider implementing a simple cache for geocoding if repeated locations are expected\n",
    "# geocode_cache = {}\n",
    "\n",
    "def get_college_name_from_location(location_str):\n",
    "    # if location_str in geocode_cache:\n",
    "    #     return geocode_cache[location_str]\n",
    "    try:\n",
    "        college = None\n",
    "        if \",\" in location_str:\n",
    "            lat_str, lon_str = location_str.split(',')\n",
    "            try:\n",
    "                latitude = float(lat_str.strip())\n",
    "                longitude = float(lon_str.strip())\n",
    "                location = geolocator.reverse((latitude, longitude), exactly_one=True, language=\"en\")\n",
    "                if location and location.raw.get('address'):\n",
    "                    address = location.raw['address']\n",
    "                    college = address.get('university') or address.get('college')\n",
    "            except ValueError:\n",
    "                return \"Error: Invalid latitude/longitude format.\"\n",
    "        else:\n",
    "            location = geolocator.geocode(location_str, exactly_one=True, language=\"en\")\n",
    "            if location and location.raw.get('address'):\n",
    "                address = location.raw['address']\n",
    "                college = address.get('university') or address.get('college')\n",
    "\n",
    "        result = college if college else \"[College name not found based on location]\"\n",
    "        # geocode_cache[location_str] = result\n",
    "        return result\n",
    "    except (GeocoderTimedOut, GeocoderServiceError) as e:\n",
    "        # geocode_cache[location_str] = f\"Error with geocoding service: {e}\"\n",
    "        return f\"Error with geocoding service: {e}\"\n",
    "    except Exception as e:\n",
    "        # geocode_cache[location_str] = f\"An unexpected error occurred during geocoding: {e}\"\n",
    "        return f\"An unexpected error occurred during geocoding: {e}\"\n",
    "\n",
    "def process_audio(audio_input):\n",
    "    if audio_input == 'live':\n",
    "        with sr.Microphone() as source:\n",
    "            print(\"Speak now...\")\n",
    "            try:\n",
    "                audio_data = r.listen(source)\n",
    "                text = r.recognize_google(audio_data)\n",
    "                return f\"Live audio transcript: {text}\"\n",
    "            except sr.UnknownValueError:\n",
    "                return \"Could not understand audio.\"\n",
    "            except sr.RequestError as e:\n",
    "                return f\"Could not request results from Google Speech Recognition service; {e}\"\n",
    "            except Exception as e:\n",
    "                return f\"Error processing live audio: {e}\"\n",
    "    else:\n",
    "        try:\n",
    "            print(f\"Attempting to process audio file: {audio_input}\")\n",
    "            audio = AudioSegment.from_file(audio_input)\n",
    "            print(f\"Audio loaded successfully. Format: {audio.format}, Channels: {audio.channels}, Rate: {audio.frame_rate}\")\n",
    "            # Convert to a format that speech_recognition likes (e.g., WAV)\n",
    "            audio = audio.set_frame_rate(16000)  # Standard sample rate for speech recognition\n",
    "            audio = audio.set_channels(1)      # Mono audio\n",
    "\n",
    "            # Export to a temporary WAV file\n",
    "            temp_wav_file = \"temp_audio.wav\"\n",
    "            audio.export(temp_wav_file, format=\"wav\")\n",
    "            print(f\"Audio converted and saved to: {temp_wav_file}\")\n",
    "\n",
    "            with sr.AudioFile(temp_wav_file) as source:\n",
    "                audio_data = r.record(source)\n",
    "                print(\"Audio data recorded from temporary file.\")\n",
    "                try:\n",
    "                    text = r.recognize_google(audio_data)\n",
    "                    os.remove(temp_wav_file)  # Clean up the temporary file\n",
    "                    return f\"Audio transcript: {text}\"\n",
    "                except sr.UnknownValueError:\n",
    "                    os.remove(temp_wav_file)\n",
    "                    return \"Could not understand audio from file.\"\n",
    "                except sr.RequestError as e:\n",
    "                    os.remove(temp_wav_file)\n",
    "                    return f\"Could not request results from Google Speech Recognition service (file); {e}\"\n",
    "        except FileNotFoundError:\n",
    "            return f\"Error: Audio file not found at '{audio_input}'.\"\n",
    "        except Exception as e:\n",
    "            return f\"Error processing audio file '{audio_input}': {e}\"\n",
    "\n",
    "def generate_report(inputs):\n",
    "    report_content = \"\"\n",
    "\n",
    "    event_name = inputs.get('event_name', '[Event Name not provided]')\n",
    "    college_name = inputs.get('college_name', '[College Name not provided]')\n",
    "\n",
    "    final_report = f\"--- Report ---\\n\\n\"\n",
    "    final_report += f\"Event: {event_name}\\n\"\n",
    "    final_report += f\"College: {college_name}\\n\\n\"\n",
    "\n",
    "    if 'images' in inputs and inputs['images']:\n",
    "        final_report += \"--- Image Analysis ---\\n\"\n",
    "        for i, image_path in enumerate(inputs['images']):\n",
    "            image_report = f\"Image {i+1}:\\n\"\n",
    "            if inputs.get('analyze_objects', False):\n",
    "                object_description = process_image_objects(image_path)\n",
    "                image_report += f\"- Object Detection: {object_description}\\n\"\n",
    "            if inputs.get('recognize_text', False):\n",
    "                text_description = process_image_text(image_path)\n",
    "                image_report += f\"- Text Recognition: {text_description}\\n\"\n",
    "            final_report += image_report + \"\\n\"\n",
    "        final_report += \"\\n\"\n",
    "\n",
    "    if 'location' in inputs:\n",
    "        final_report += \"--- Location Information ---\\n\"\n",
    "        final_report += f\"Provided Location: {inputs['location']}\\n\"\n",
    "        # Only call geocoding if a college name wasn't directly provided or if you specifically need the location's college\n",
    "        if college_name == '[College Name not provided]':\n",
    "            college_name_from_location = get_college_name_from_location(inputs['location'])\n",
    "            final_report += f\"College Name (from location): {college_name_from_location}\\n\\n\"\n",
    "        else:\n",
    "            final_report += f\"College Name (from location): [Geocoding skipped as college name was provided]\\n\\n\"\n",
    "\n",
    "    if 'feedback' in inputs:\n",
    "        final_report += \"--- Feedback ---\\n\"\n",
    "        final_report += f\"User Feedback: {inputs['feedback']}\\n\\n\"\n",
    "\n",
    "    if 'audio' in inputs:\n",
    "        final_report += \"--- Audio Information ---\\n\"\n",
    "        if inputs['audio'] == 'live':\n",
    "            final_report += \"Audio Source: Live Microphone Input\\n\"\n",
    "        else:\n",
    "            final_report += f\"Audio Path: {inputs['audio']}\\n\"\n",
    "        audio_transcript = process_audio(inputs['audio'])\n",
    "        final_report += f\"Audio Transcript: {audio_transcript}\\n\\n\"\n",
    "\n",
    "    final_report += \"--- End of Report ---\"\n",
    "\n",
    "    return final_report\n",
    "\n",
    "def save_report_to_file(report):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"report_{timestamp}.txt\"\n",
    "    try:\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(report)\n",
    "        print(f\"\\nReport saved to '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving report to file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = get_input_paths()\n",
    "    if inputs and 'images' in inputs:\n",
    "        report = generate_report(inputs)\n",
    "        print(\"\\n--- Generated Report ---\")\n",
    "        print(report)\n",
    "        save_report_to_file(report)\n",
    "    else:\n",
    "        print(\"No valid inputs received. Cannot generate a report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d602783e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rouge in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: six in c:\\users\\jyoth\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from rouge) (1.17.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install rouge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "95f036ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Neither CUDA nor MPS are available - defaulting to CPU. Note: This module is much faster with a GPU.\n",
      "c:\\Users\\jyoth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "c:\\Users\\jyoth\\AppData\\Local\\Programs\\Python\\Python313\\Lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Image Input ---\n",
      "\n",
      "--- Optional Inputs ---\n",
      "\n",
      "--- Generated Prompt for API ---\n",
      "The Algoveda event, hosted by VBIT, appears to have involved elements as indicated by text recognition identified \"AlgoVeda, VBIT, AlgoVeda\", text recognition identified \"VBIT, AlgoVeda\". The provided location for the event was Vignana Bharathi Institute of Technology,Ghatkesar,Hyderabad in An unexpected error occurred during geocoding: too many values to unpack (expected 2). User feedback noted: \"It was a nice coding competition which has level 7.I got to show my coding skills in level 7. Till level 6 it was very easy.\". Please generate a concise report summarizing these details in a natural-sounding paragraph.\n",
      "\n",
      "API Generated Report saved to 'api_report_20250502_150451.txt'\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import re\n",
    "from PIL import Image\n",
    "import os\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.models as models\n",
    "import requests\n",
    "import json\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut, GeocoderServiceError\n",
    "import speech_recognition as sr\n",
    "from datetime import datetime\n",
    "import easyocr  # Import the easyocr library\n",
    "from pydub import AudioSegment  # Import pydub for audio format conversion\n",
    "\n",
    "client = OpenAI(\n",
    "    base_url=\"https://openrouter.ai/api/v1\",\n",
    "    api_key=\"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\",\n",
    ")\n",
    "MODEL_NAME = \"google/gemma-3-12b-it:free\"\n",
    "\n",
    "# Initialize easyocr reader ONCE\n",
    "try:\n",
    "    reader = easyocr.Reader(['en'])  # You can add other languages here, e.g., ['en', 'hi']\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing easyocr: {e}\")\n",
    "    reader = None\n",
    "\n",
    "# Initialize geolocator\n",
    "geolocator = Nominatim(user_agent=\"multimedia_report_generator\")\n",
    "\n",
    "# Load pre-trained model and labels ONCE\n",
    "model = None\n",
    "transform = None\n",
    "imagenet_classes = []\n",
    "try:\n",
    "    model = models.resnet18(pretrained=True)\n",
    "    model.eval()\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    try:\n",
    "        with open(\"imagenet_classes.txt\", \"r\") as f:\n",
    "            imagenet_classes = [s.strip() for s in f.readlines()]\n",
    "    except FileNotFoundError:\n",
    "        print(\"Warning: imagenet_classes.txt not found. Downloading...\")\n",
    "        url = \"https://raw.githubusercontent.com/anishathalye/imagenet-simple-labels/master/imagenet-simple-labels.json\"\n",
    "        try:\n",
    "            response = requests.get(url)\n",
    "            response.raise_for_status()\n",
    "            imagenet_labels_json = response.json()\n",
    "            if isinstance(imagenet_labels_json, dict):\n",
    "                imagenet_classes = list(imagenet_labels_json.values())\n",
    "            elif isinstance(imagenet_labels_json, list):\n",
    "                imagenet_classes = imagenet_labels_json\n",
    "            else:\n",
    "                print(\"Error: Unexpected format for downloaded ImageNet labels.\")\n",
    "                imagenet_classes = [\"unknown\"] * 1000\n",
    "            with open(\"imagenet_classes.txt\", \"w\") as f:\n",
    "                for label in imagenet_classes:\n",
    "                    f.write(label + \"\\n\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"Error downloading ImageNet labels: {e}\")\n",
    "            imagenet_classes = [\"unknown\"] * 1000\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error decoding downloaded JSON: {e}\")\n",
    "            imagenet_classes = [\"unknown\"] * 1000\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading ImageNet class labels: {e}\")\n",
    "        imagenet_classes = [\"unknown\"] * 1000\n",
    "except Exception as e:\n",
    "    print(f\"Error initializing PyTorch models or transforms: {e}\")\n",
    "    model = None\n",
    "    transform = None\n",
    "    imagenet_classes = [\"Error\"] * 1000\n",
    "\n",
    "def get_input_paths():\n",
    "    input_paths = {}\n",
    "\n",
    "    # Event Name (Mandatory)\n",
    "    event_name = input(\"Enter the name of the event: \")\n",
    "    input_paths['event_name'] = event_name\n",
    "\n",
    "    # Image Input (Mandatory)\n",
    "    image_paths = []\n",
    "    print(\"\\n--- Image Input ---\")\n",
    "    while True:\n",
    "        image_path = input(\"Enter the path to an image file (or type 'done' if you've entered all images): \")\n",
    "        if image_path.lower() == 'done':\n",
    "            break\n",
    "        if os.path.exists(image_path):\n",
    "            image_paths.append(image_path)\n",
    "        else:\n",
    "            print(f\"Error: Image path '{image_path}' does not exist.\")\n",
    "    if not image_paths:\n",
    "        print(\"Error: At least one image is required.\")\n",
    "        return None\n",
    "    input_paths['images'] = image_paths\n",
    "\n",
    "    # College Name (Mandatory)\n",
    "    college_name_input = input(\"Enter the name of the college: \")\n",
    "    input_paths['college_name'] = college_name_input\n",
    "\n",
    "    # Optional Inputs\n",
    "    print(\"\\n--- Optional Inputs ---\")\n",
    "    # Removed analyze_objects question\n",
    "    input_paths['analyze_objects'] = False # Set to False by default\n",
    "\n",
    "    recognize_text = input(\"Do you want to recognize text in the image? (yes/no): \").lower()\n",
    "    input_paths['recognize_text'] = recognize_text == 'yes'\n",
    "\n",
    "    add_feedback = input(\"Do you want to provide feedback text? (yes/no): \").lower()\n",
    "    if add_feedback == 'yes':\n",
    "        feedback_text = input(\"Enter the feedback text: \")\n",
    "        input_paths['feedback'] = feedback_text\n",
    "\n",
    "    add_location = input(\"Do you want to provide location information? (yes/no): \").lower()\n",
    "    if add_location == 'yes':\n",
    "        location_input = input(\"Enter the location (e.g., latitude,longitude or a place name): \")\n",
    "        input_paths['location'] = location_input\n",
    "\n",
    "    return input_paths\n",
    "\n",
    "def process_image_objects(image_path):\n",
    "    if model is None or transform is None or not imagenet_classes or \"Error\" in imagenet_classes:\n",
    "        return \"Error: PyTorch model or dependencies not initialized correctly.\"\n",
    "    try:\n",
    "        img = Image.open(image_path).convert('RGB')\n",
    "        img_t = transform(img)\n",
    "        batch_t = torch.unsqueeze(img_t, 0)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            output = model(batch_t)\n",
    "\n",
    "        _, indices = torch.sort(output, descending=True)\n",
    "        probabilities = torch.nn.functional.softmax(output, dim=1)[0]\n",
    "\n",
    "        top5_preds = [(imagenet_classes[idx], probabilities[idx].item() * 100) for idx in indices[0][:5]]\n",
    "        description = f\"likely containing {', '.join([pred[0] for pred in top5_preds])}\"\n",
    "        return description\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Image file not found at '{image_path}'.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image '{image_path}' for object detection: {e}\"\n",
    "\n",
    "def process_image_text(image_path):\n",
    "    if reader is None:\n",
    "        return \"Error: easyocr not initialized.\"\n",
    "    try:\n",
    "        result = reader.readtext(image_path)\n",
    "        if result:\n",
    "            recognized_text = \", \".join([detection[1] for detection in result])\n",
    "            return f\"identified \\\"{recognized_text}\\\"\"\n",
    "        else:\n",
    "            return \"identified no specific text\"\n",
    "    except FileNotFoundError:\n",
    "        return f\"Error: Image file not found at '{image_path}' for text recognition.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error processing image '{image_path}' for text recognition with easyocr: {e}\"\n",
    "\n",
    "def get_college_name_from_location(location_str):\n",
    "    try:\n",
    "        college = None\n",
    "        if \",\" in location_str:\n",
    "            lat_str, lon_str = location_str.split(',')\n",
    "            try:\n",
    "                latitude = float(lat_str.strip())\n",
    "                longitude = float(lon_str.strip())\n",
    "                location = geolocator.reverse((latitude, longitude), exactly_one=True, language=\"en\")\n",
    "                if location and location.raw.get('address'):\n",
    "                    address = location.raw['address']\n",
    "                    college = address.get('university') or address.get('college')\n",
    "            except ValueError:\n",
    "                return \"Error: Invalid latitude/longitude format.\"\n",
    "        else:\n",
    "            location = geolocator.geocode(location_str, exactly_one=True, language=\"en\")\n",
    "            if location and location.raw.get('address'):\n",
    "                address = location.raw['address']\n",
    "                college = address.get('university') or address.get('college')\n",
    "\n",
    "        return college if college else location_str  # Return location if college not found\n",
    "    except (GeocoderTimedOut, GeocoderServiceError) as e:\n",
    "        return f\"Error with geocoding service: {e}\"\n",
    "    except Exception as e:\n",
    "        return f\"An unexpected error occurred during geocoding: {e}\"\n",
    "\n",
    "def generate_report_prompt(inputs):\n",
    "    report_parts = []\n",
    "\n",
    "    event_name = inputs.get('event_name', 'the event')\n",
    "    college_name = inputs.get('college_name', 'the institution')\n",
    "    report_parts.append(f\"The {event_name} event, hosted by {college_name},\")\n",
    "\n",
    "    image_details = []\n",
    "    if 'images' in inputs and inputs['images']:\n",
    "        for i, image_path in enumerate(inputs['images']):\n",
    "            details = []\n",
    "            # Object detection is now always False, so this part won't be included\n",
    "            # if inputs.get('analyze_objects', False):\n",
    "            #     object_description = process_image_objects(image_path)\n",
    "            #     details.append(f\"images {object_description}\")\n",
    "            if inputs.get('recognize_text', False):\n",
    "                text_description = process_image_text(image_path)\n",
    "                details.append(f\"text recognition {text_description}\")\n",
    "            if details:\n",
    "                image_details.append(\" and \".join(details))\n",
    "\n",
    "        if image_details:\n",
    "            report_parts.append(f\"appears to have involved elements as indicated by {', '.join(image_details)}.\")\n",
    "        else:\n",
    "            report_parts.append(\"appears to have occurred.\")\n",
    "\n",
    "    else:\n",
    "        report_parts.append(\"appears to have occurred.\")\n",
    "\n",
    "    location_info = None\n",
    "    if 'location' in inputs:\n",
    "        location_str = inputs['location']\n",
    "        resolved_college_name = get_college_name_from_location(location_str)\n",
    "        if resolved_college_name and resolved_college_name.lower() != college_name.lower() and \"[College name not found based on location]\" not in resolved_college_name and \"Error\" not in resolved_college_name:\n",
    "            location_info = f\"The provided location for the event was {location_str} in {resolved_college_name}.\"\n",
    "        else:\n",
    "            location_info = f\"The provided location for the event was {location_str}.\"\n",
    "        report_parts.append(location_info)\n",
    "    elif college_name != '[College Name not provided]':\n",
    "        report_parts.append(f\"The event was hosted at {college_name}.\")\n",
    "\n",
    "    if 'feedback' in inputs:\n",
    "        report_parts.append(f\"User feedback noted: \\\"{inputs['feedback']}\\\".\")\n",
    "\n",
    "    final_prompt = \" \".join(report_parts)\n",
    "    return final_prompt + \" Please generate a concise report summarizing these details in a natural-sounding paragraph.\"\n",
    "\n",
    "def generate_and_save_api_report(prompt):\n",
    "    try:\n",
    "        completion = client.chat.completions.create(\n",
    "            model=MODEL_NAME,\n",
    "            messages=[\n",
    "                {\"role\": \"user\", \"content\": prompt}\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if completion and completion.choices and len(completion.choices) > 0 and completion.choices[0].message:\n",
    "            generated_report = completion.choices[0].message.content.strip()\n",
    "            timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "            filename = f\"api_report_{timestamp}.txt\"\n",
    "            try:\n",
    "                with open(filename, \"w\") as outfile:\n",
    "                    outfile.write(generated_report)\n",
    "                print(f\"\\nAPI Generated Report saved to '{filename}'\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error saving API generated report to file: {e}\")\n",
    "        else:\n",
    "            print(\"Error: Could not retrieve a valid report from the API.\")\n",
    "            if completion:\n",
    "                print(f\"Completion object: {completion}\")\n",
    "            else:\n",
    "                print(\"Completion object is None.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred during API call: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    inputs = get_input_paths()\n",
    "    if inputs and 'images' in inputs:\n",
    "        prompt = generate_report_prompt(inputs)\n",
    "        print(\"\\n--- Generated Prompt for API ---\")\n",
    "        print(prompt)\n",
    "        generate_and_save_api_report(prompt)\n",
    "    else:\n",
    "        print(\"No valid inputs received. Cannot generate a report.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d33afd26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Database tables 'input' and 'output' created (if they didn't exist).\n",
      "\n",
      "--- Generated Report ---\n",
      "The analysis of the provided data reveals several key\n",
      "characteristics. --- Report ---, Event: Algoveda, College: VBIT, ---\n",
      "Image Analysis ---, Image 1:, - Text Recognition: Recognized text:,\n",
      "AlgoVeda, VBIT, AlgoVeda, Image 2:, - Text Recognition: Recognized\n",
      "text:, VBIT, AlgoVeda, --- Location Information ---, Provided\n",
      "Location: Vignana Bharathi Institute of\n",
      "Technology,Ghatkesar,Hyderabad, College Name (from location):\n",
      "[Geocoding skipped as college name was provided], --- Feedback ---,\n",
      "User Feedback: It was a nice coding competition, --- End of Report\n",
      "---. Considering these individual findings, a broader interpretation\n",
      "emerges. This feature contributes to the overall understanding and\n",
      "may hold further implications. This feature contributes to the\n",
      "overall understanding and may hold further implications..\n",
      "\n",
      "Report saved to 'report_20250502_142053.txt'\n",
      "Report content saved to the 'output' table.\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "import os\n",
    "import random\n",
    "import mysql.connector\n",
    "\n",
    "# Database configuration\n",
    "DB_HOST = \"localhost\"\n",
    "DB_USER = \"root\"  # Replace with your MySQL username\n",
    "DB_PASSWORD = \"Adithya@2005\"  # Replace with your MySQL password\n",
    "DB_NAME = \"project1\"\n",
    "\n",
    "def create_tables():\n",
    "    try:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=DB_HOST,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            database=DB_NAME\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "\n",
    "        # Create input table if it doesn't exist\n",
    "        mycursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS input (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                extracted_features_path VARCHAR(255),\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        # Create output table if it doesn't exist\n",
    "        mycursor.execute(\"\"\"\n",
    "            CREATE TABLE IF NOT EXISTS output (\n",
    "                id INT AUTO_INCREMENT PRIMARY KEY,\n",
    "                input_id INT,\n",
    "                report_content TEXT,\n",
    "                timestamp DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "                FOREIGN KEY (input_id) REFERENCES input(id)\n",
    "            )\n",
    "        \"\"\")\n",
    "\n",
    "        mydb.commit()\n",
    "        mycursor.close()\n",
    "        mydb.close()\n",
    "        print(\"Database tables 'input' and 'output' created (if they didn't exist).\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error creating tables: {err}\")\n",
    "\n",
    "def get_input_paths():\n",
    "    input_paths = {}\n",
    "    extracted_features_path = input(\"Enter the path to the file containing extracted features (.txt): \").strip()\n",
    "\n",
    "    if not os.path.exists(extracted_features_path):\n",
    "        print(f\"Error: File not found at '{extracted_features_path}'.\")\n",
    "        return None\n",
    "    input_paths['extracted_features_path'] = extracted_features_path\n",
    "    return input_paths\n",
    "\n",
    "def insert_input_data(inputs):\n",
    "    try:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=DB_HOST,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            database=DB_NAME\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "\n",
    "        sql = \"INSERT INTO input (extracted_features_path) VALUES (%s)\"\n",
    "        val = (inputs.get('extracted_features_path'),)\n",
    "        mycursor.execute(sql, val)\n",
    "        mydb.commit()\n",
    "        input_id = mycursor.lastrowid\n",
    "        mycursor.close()\n",
    "        mydb.close()\n",
    "        return input_id\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error inserting input data: {err}\")\n",
    "        return None\n",
    "\n",
    "def insert_output_data(input_id, report):\n",
    "    try:\n",
    "        mydb = mysql.connector.connect(\n",
    "            host=DB_HOST,\n",
    "            user=DB_USER,\n",
    "            password=DB_PASSWORD,\n",
    "            database=DB_NAME\n",
    "        )\n",
    "        mycursor = mydb.cursor()\n",
    "\n",
    "        sql = \"INSERT INTO output (input_id, report_content) VALUES (%s, %s)\"\n",
    "        val = (input_id, report)\n",
    "        mycursor.execute(sql, val)\n",
    "        mydb.commit()\n",
    "        mycursor.close()\n",
    "        mydb.close()\n",
    "        print(\"Report content saved to the 'output' table.\")\n",
    "    except mysql.connector.Error as err:\n",
    "        print(f\"Error inserting output data: {err}\")\n",
    "\n",
    "def generate_paragraph_report(inputs):\n",
    "    extracted_features_path = inputs.get('extracted_features_path')\n",
    "    report_paragraph = \"\"\n",
    "\n",
    "    try:\n",
    "        with open(extracted_features_path, \"r\") as f:\n",
    "            extracted_features = [line.strip() for line in f.readlines() if line.strip()]\n",
    "\n",
    "        if extracted_features:\n",
    "            report_paragraph += \"The analysis of the provided data reveals several key characteristics. \"\n",
    "            report_paragraph += \", \".join(extracted_features) + \". \"\n",
    "\n",
    "            # Generate AI content based on extracted features\n",
    "            ai_elaboration = []\n",
    "            for feature in extracted_features:\n",
    "                if \"image contains\" in feature.lower():\n",
    "                    entity = feature.split(\"contains\")[-1].strip()\n",
    "                    ai_elaboration.append(f\"The presence of a '{entity}' suggests a visual focus on this element, potentially indicating its importance within the context.\")\n",
    "                elif \"dominant color\" in feature.lower():\n",
    "                    color = feature.split(\"is\")[-1].strip()\n",
    "                    ai_elaboration.append(f\"The dominant color being '{color}' could influence the overall mood or convey specific symbolic meanings.\")\n",
    "                elif \"detected object\" in feature.lower():\n",
    "                    obj = feature.split(\":\")[-1].strip()\n",
    "                    ai_elaboration.append(f\"The detection of a '{obj}' as a significant object warrants further consideration of its role.\")\n",
    "                elif \"confidence score\" in feature.lower():\n",
    "                    score = float(feature.split(':')[-1].strip())\n",
    "                    if score > 0.8:\n",
    "                        ai_elaboration.append(f\"With a high confidence score of {score:.2f}, this particular observation is deemed highly reliable.\")\n",
    "                    else:\n",
    "                        ai_elaboration.append(f\"The confidence score of {score:.2f} suggests a moderate level of certainty for this finding.\")\n",
    "                else:\n",
    "                    ai_elaboration.append(f\"This feature contributes to the overall understanding and may hold further implications.\")\n",
    "\n",
    "            if ai_elaboration:\n",
    "                report_paragraph += \"Considering these individual findings, a broader interpretation emerges. \"\n",
    "                report_paragraph += \" \".join(random.sample(ai_elaboration, min(len(ai_elaboration), 2))) + \". \"\n",
    "\n",
    "            report_paragraph = report_paragraph.strip()\n",
    "            # Ensure at least 3 lines (by adding more sentences)\n",
    "            while report_paragraph.count('.') < 2 and ai_elaboration:\n",
    "                report_paragraph += random.choice(ai_elaboration) + \". \"\n",
    "                report_paragraph = report_paragraph.strip()\n",
    "\n",
    "            if report_paragraph.count('.') < 2:\n",
    "                report_paragraph += \"In conclusion, the identified features collectively offer valuable insights into the subject matter.\"\n",
    "\n",
    "        else:\n",
    "            report_paragraph = \"No extracted features were found in the provided file.\"\n",
    "\n",
    "        return report_paragraph.strip()\n",
    "\n",
    "    except FileNotFoundError:\n",
    "        return \"Error: Extracted features file not found.\"\n",
    "    except Exception as e:\n",
    "        return f\"Error reading extracted features file: {e}\"\n",
    "\n",
    "def save_report_to_file(report):\n",
    "    timestamp = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    filename = f\"report_{timestamp}.txt\"\n",
    "    try:\n",
    "        with open(filename, \"w\") as f:\n",
    "            f.write(report)\n",
    "        print(f\"\\nReport saved to '{filename}'\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error saving report to file: {e}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Create the tables if they don't exist\n",
    "    create_tables()\n",
    "\n",
    "    inputs = get_input_paths()\n",
    "    if inputs:\n",
    "        input_id = insert_input_data(inputs)\n",
    "        if input_id:\n",
    "            report = generate_paragraph_report(inputs)\n",
    "            print(\"\\n--- Generated Report ---\")\n",
    "            # Print the report with line breaks for better readability\n",
    "            formatted_report = \"\"\n",
    "            sentence_endings = ['.', '!', '?']\n",
    "            current_line = \"\"\n",
    "            for word in report.split():\n",
    "                if len(current_line) + len(word) + 1 <= 70:  # Adjust line width as needed\n",
    "                    current_line += (word + \" \")\n",
    "                else:\n",
    "                    formatted_report += current_line.strip() + \"\\n\"\n",
    "                    current_line = word + \" \"\n",
    "            formatted_report += current_line.strip()\n",
    "            print(formatted_report)\n",
    "            save_report_to_file(report)\n",
    "            insert_output_data(input_id, report)\n",
    "        else:\n",
    "            print(\"Failed to record input data.\")\n",
    "    else:\n",
    "        print(\"No valid input received.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
